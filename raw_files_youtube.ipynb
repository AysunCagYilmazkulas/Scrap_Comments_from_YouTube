{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient.discovery import build\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'Market Communications'\n",
    "key_code = 'market_communications_'\n",
    "\n",
    "country = 'United Kingdom'\n",
    "\n",
    "# Keyword list of the data to be accessed\n",
    "keyword_list = ['AI',\n",
    "                'Autonomous',\n",
    "                'Biotech',\n",
    "                'Blockchain',\n",
    "                'Crypto',\n",
    "                'EdTech',\n",
    "                'Fintech',\n",
    "                'Healthtech',\n",
    "                'Hospitality',\n",
    "                'Medtech',\n",
    "                'Robotics',\n",
    "                'Tourism',\n",
    "                'Travel']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyC-734KDByCEEaDNQAr7nIkIg4Hv8leCpk\"\n",
    "regionCode = 'UK'\n",
    "\n",
    "# Enter the key number to be selected from the keywords list\n",
    "key_no = int(input('Keyword number: '))\n",
    "keyword = key + ' and ' + keyword_list[key_no] + ' and ' + country\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "request = youtube.search().list(part='snippet',\n",
    "                                q = keyword,\n",
    "                                type = 'video',\n",
    "                                regionCode = regionCode,\n",
    "                                maxResults = 50)\n",
    "\n",
    "result = request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(comment):\n",
    "    comment = comment.lower()\n",
    "    sent = re.sub(r\"<[^<]+?>\", \"\", comment)  # Remove html tags\n",
    "    sent = re.sub(\"&quot;\", \"'\", sent)  # Replace quotes\n",
    "    sent = re.sub(r\"http\\S+\", \"\", sent)\n",
    "    sent = re.sub(r\"www\\S+\", \"\", sent)\n",
    "    sent = re.sub(r\"#\\S+\", \"\", sent)\n",
    "    sent = re.sub(r\"[^a-z]+\", \" \", sent)\n",
    "    sent = re.sub(r\"[@]+\", \"\", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_file(file_name, keyword ,regionCode):  \n",
    "\n",
    "    video_path = 'https://www.youtube.com/watch?v='\n",
    "\n",
    "    # Creation of the csv file for transferring the data\n",
    "    with open(file_name, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Keyword', 'Url', 'Content', 'Comment', 'Authors_name','Comment_date', 'Country', 'Source'])\n",
    "\n",
    "        # Accessing information about Youtube videos\n",
    "        for item in result['items']:\n",
    "            keyword = keyword\n",
    "            videoId = item['id']['videoId']\n",
    "            content = item['snippet']['description']\n",
    "            country = regionCode\n",
    "            source = 'YouTube'\n",
    "            request = youtube.commentThreads().list(\n",
    "                part = 'snippet',\n",
    "                videoId = videoId\n",
    "            )\n",
    "            try:   \n",
    "                response = request.execute()\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for item in response['items']:\n",
    "\n",
    "                # Accessing the comments in the video and information about them\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                author = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "                c_date = item['snippet']['topLevelComment']['snippet']['publishedAt'][:10]\n",
    "\n",
    "                if(cleaning_text(comment) == ' '):\n",
    "                    pass\n",
    "                elif(cleaning_text(comment) == ''):\n",
    "                    pass\n",
    "                else:\n",
    "\n",
    "                    # Exporting data to the created csv file\n",
    "                    writer.writerow([keyword, \n",
    "                                    video_path + videoId, \n",
    "                                    content, \n",
    "                                    cleaning_text(comment), \n",
    "                                    author, \n",
    "                                    c_date, \n",
    "                                    country, \n",
    "                                    source])\n",
    "\n",
    "# create_raw_file(key_code + keyword_list[key_no].lower() + '_unitedkingdom.csv',keyword,regionCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_files/raw_file_UK/market_communications_\n"
     ]
    }
   ],
   "source": [
    "print('raw_files/raw_file_UK/' + key_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_raw_files(keyword,country):\n",
    "    \n",
    "    # Setting the path for joining multiple files\n",
    "    file_path = 'raw_files/raw_file_US/' \n",
    "    append_path = 'raw_files/raw_file_US/'\n",
    "\n",
    "    files = os.path.join(file_path, \"*.csv\")\n",
    "\n",
    "    # List of merged files returned\n",
    "    files = glob.glob(files)\n",
    "\n",
    "    # Joining files with concat and read_csv\n",
    "    df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "\n",
    "    # Exporting combined data to csv file\n",
    "    # df.to_csv(append_path + 'combined_' + keyword + country + '.csv', index = False)      \n",
    "    df.to_csv('rawfile_youtube_unitedstates.csv', index = False)      # For all combined\n",
    "\n",
    "# combined_raw_files('product_lead_growth','_US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d0fe0db539196317f852afcf4dd477ba0395eecb8256e5265d1ca210e597875"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
